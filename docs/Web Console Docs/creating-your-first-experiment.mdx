---
sidebar_position: 2
---

import FutureDate from "../../src/components/FutureDate";

# Creating An Experiment

How about we start creating some experiments? At the top of the dashboard, you
will find the **New Experiment** button. Here you will be able to fine tune,
edit and start your experiment.

## Experiment Name

The experiment name can be anything that you want! As it will be used in your
code, we recommend using a keyword-like name with underscores. For example,
`large_homepage_carousel`.

## Traffic Allocation

The traffic allocation is the total amount of audience who will experience the
experiment, including the control group. Usually, this is kept at 100% unless
the change is considered dangerous. In which case, you could start it at 10%,
move it up to 50% and eventually to 100% as you grow more confident in the
change.

## Tracking Unit

The experiment's tracking unit is the unique identifier that will be used to
assign the user to a variant.

If the experiment is to be run across multiple platforms (Such as iOS, Android,
Web, Email etc.), then this unit should be available on all of them. Most
likely, the `user_id` of the authenticated user.

Conversely, if you wish for a user to experience different variants, depending
on their device, you could use their `device_id` as a unit.

Even further, to avoid experiment biases from users talking to eachother about
their experience, companies such as LinkedIn, group their users into clusters
and would use a `cluster_id` as their tracking unit.

## Applications

Applications are the places where this experiment will be run. These could be
"android", "ios" and "web", for example, and are created in the dashboard
settings.

## Variants

The variants section is where you will choose your amount of variants, the
percentage of traffic that each variant will have, your variant names and set
any variant variables which can be used in your code.

You can have up to 4 variants at any one time and your split percentage can be
whatever you want. But note, the split percentage cannot be changed after an
experiment has started running without biasing the data. If you wish to ease-in
an experiment, it's better to use the [traffic allocation](#traffic-allocation)
option instead.

:::caution
The more variants you have, the less traffic each variant will be
exposed to.
:::

### Variant Variables

Variant variables can be used to automate your experiments. If you, for
example use a configuration file, you can pass a variant variable here and
have it overwrite your code. See
[treatment variables](/docs/sdk%20documentation/basic-usage#treatment-variables)
in the SDK Documentation for more information.

## Metrics

Your primary metric is the statistic which is used to make a decision on your
experiment and are inherantly linked to [goals](/docs/goals).

Secondary metrics are not used to make a decision on your experiment, but they
may be affected by it. Setting them here allows for you to easily visualise
them in the [experiment view](/docs/experiment-view).

## Minimum Detectable Effect

The Minimum Detectable Effect (MDE) is used to calculate the minimum required
sample-size for your experiments and therefore, how long the experiment should
run for.

To calculate the MDE of your experiment, you can use the
[Evan Millar Sample-Size Calculator](https://www.evanmiller.org/ab-testing/sample-size.html).

## Targeting Audience

Here you can define an audience who will experience the experiment. You could,
for example, only test the experiment on British users. In this case you might
set the filter group to:

- language IS EQUAL en-gb

  AND

- country IS EQUAL gb

### Strict Mode

When strict mode is **on**, only users in the filter groups will be able to
participate in the experiment. They will be shown the control variant, but
their data will not be tracked.

When strict mode is **off**, any user can participate in the experiment, but
the web console may warn you that your experiment is being shown to the wrong
people.

## Metadata

The metadata section allows you to select the owners of this experiment and
assign it to a particular team.

### Tags

Tags are useful for searching for your experiments in the future and can be
named anything you like. Often it can be useful to prefix your tags with the
meaning of that tag. Some examples of tags could be:

- `stack:backend`
- `theme:urgency`
- `location:navbar`
- `psychological:trust`

These allow for you to filter your experiments in the experiments list page,
but also give you an insight into why that experiment was tagged as such.

## Description

When creating a new experiment, the description section acts as your contract
for the test. Allowing you to define for yourself and your team why you are
running this experiment, what you hope for the result to be and what will be
done after any of the experiment's possible outcomes.

### Hypothesis

Your hypothesis is the assumed answer to the question that the experiment is asking.

For example:

> Based on the fact that the color red is one of the most visible colors in
> the color spectrum, we believe that red call-to-action buttons are more
> noticeable on screen than blue ones.

### Prediction

Your prediction states what will happen if your hypothesis proves to be true.

For example:

> Changing our call-to-action buttons to red will cause a higher click-through-rate
> from our visitors.

### Purpose

Your experiment's purpose is the reason for why this experiment should take
place. What customer or business needs are being addressed.

For example:

> Optimizing the efficiency of our sales pipeline.

### Implementation Details

In your implementation details, you can define the parameters of your experiment's implementation, like:

- How long it will take to implement
- What's the impact that we can expect from this implementation?
- What is the minimum impact that we need to see in order to keep this experiment?

For example:

> This implementation will be completed by <FutureDate daysAhead={2}/>.
>
> We can expect an increase of up to 25% in our homepage click-through-rate.
>
> At a minimum, we should see a 5% increase if we are to keep the change.

### Action Points

Action Points are a list of actions that will be taken depending on the experiment's outcome.

For example:

> If the primary metric is significantly positive we will keep the experiment.
>
> If the primary metric is significantly negative we will drop the experiment.
>
> If the primary metric is inconclusive we will drop the experiment.
